{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e62b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a8834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89681a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb19c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='../Data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53506c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../Data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b7ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(root='../Data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "660b22a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../Data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749483ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3dbeae",
   "metadata": {},
   "source": [
    "# Convolutional Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c7c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 6, 3, 1) # ----> 6 filters --> pooling --> Conv2 : th output channel will be 6\n",
    "\"\"\"\n",
    "In the layer, we did not add padding, coz in MNIST data, all information on center, so no plm if we loss the border of image\n",
    "\"\"\"\n",
    "# the 6 for input channel com from Conv1, 16 filter (optional)\n",
    "conv2 = nn.Conv2d(6, 16, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc27472",
   "metadata": {},
   "source": [
    "# First Batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4acff501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first batch of data\n",
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92e0dac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0729a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train.view(1, 1, 28, 28) # change it to 4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d06250",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa99a85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 26, 26])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "\n",
    "# the output will be\n",
    "# [ Number of sample,\n",
    "#   Number of channel(NO.Filter that applied),\n",
    "#   the output size (will be different coz we loss some data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0183652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9a50d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 13, 13])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "\n",
    "# the output will be\n",
    "# [ Number of sample,\n",
    "#   Number of channel(NO.Filter that applied),\n",
    "#   the output size (will be different coz we apply Max_Pooling with 2*2, that mean cut the size ti half)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c86e3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25c3ea23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 11, 11])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4176260",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.max_pool2d(x, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddea6b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11be2ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the data: To fit it into our model, should be flatten\n",
    "x.view(-1, 16 * 5 * 5).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a955db5",
   "metadata": {},
   "source": [
    "# Create / Build oue MODEL with CNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8fd7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_sz = 5*5*16, out_sz=10, layers=[120, 84]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN layers \n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2= nn.Conv2d(6, 16, 3, 1) # the output will be [1, 16, 5, 5]  --> should reshape it before fit it into full connecting layers \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Full connect Linear Layers \n",
    "        self.fc1 = nn.Linear(in_sz, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0], layers[1])    \n",
    "        self.fc3 = nn.Linear(layers[1], out_sz) \n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 16 * 5 * 5) # Should be flatten to fit it to full connection layer \n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X)) \n",
    "        X = self.fc3(X)\n",
    "        \n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19acae9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f48ba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "6\n",
      "864\n",
      "16\n",
      "48000\n",
      "120\n",
      "10080\n",
      "84\n",
      "840\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d94231a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters =  60074\n"
     ]
    }
   ],
   "source": [
    " print('Total Parameters = ', 54 +6 +864 +16 + 48000 +120 +10080 +84 +840 +10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba77bc",
   "metadata": {},
   "source": [
    "# Set the Loss Function and the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ec62dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c69b229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  batch: 600  loss: 0.04255055636167526  accuracy: 7.848333333333334\n",
      "Epoch: 0  batch: 1200  loss: 0.07605954259634018  accuracy: 8.5825\n",
      "Epoch: 0  batch: 1800  loss: 0.363738477230072  accuracy: 8.866111111111111\n",
      "Epoch: 0  batch: 2400  loss: 0.026480620726943016  accuracy: 9.047916666666667\n",
      "Epoch: 0  batch: 3000  loss: 0.00858532078564167  accuracy: 9.164\n",
      "Epoch: 0  batch: 3600  loss: 0.0012412868672981858  accuracy: 9.248055555555556\n",
      "Epoch: 0  batch: 4200  loss: 0.5668128728866577  accuracy: 9.314761904761905\n",
      "Epoch: 0  batch: 4800  loss: 0.031286485493183136  accuracy: 9.359791666666666\n",
      "Epoch: 0  batch: 5400  loss: 0.014834213070571423  accuracy: 9.401851851851852\n",
      "Epoch: 0  batch: 6000  loss: 0.041800253093242645  accuracy: 9.433166666666667\n",
      "Epoch: 1  batch: 600  loss: 0.02671869657933712  accuracy: 9.78\n",
      "Epoch: 1  batch: 1200  loss: 0.033834896981716156  accuracy: 9.785833333333333\n",
      "Epoch: 1  batch: 1800  loss: 0.0015030563808977604  accuracy: 9.786111111111111\n",
      "Epoch: 1  batch: 2400  loss: 0.011906487867236137  accuracy: 9.784583333333334\n",
      "Epoch: 1  batch: 3000  loss: 0.35082095861434937  accuracy: 9.787666666666667\n",
      "Epoch: 1  batch: 3600  loss: 0.0012757645454257727  accuracy: 9.79111111111111\n",
      "Epoch: 1  batch: 4200  loss: 0.0006777596427127719  accuracy: 9.797142857142857\n",
      "Epoch: 1  batch: 4800  loss: 0.0007250859634950757  accuracy: 9.795625\n",
      "Epoch: 1  batch: 5400  loss: 0.0011308582033962011  accuracy: 9.797592592592592\n",
      "Epoch: 1  batch: 6000  loss: 0.08920401334762573  accuracy: 9.797166666666667\n",
      "Epoch: 2  batch: 600  loss: 0.001029383041895926  accuracy: 9.878333333333334\n",
      "Epoch: 2  batch: 1200  loss: 0.0013868086971342564  accuracy: 9.869166666666667\n",
      "Epoch: 2  batch: 1800  loss: 0.0004451941349543631  accuracy: 9.856111111111112\n",
      "Epoch: 2  batch: 2400  loss: 0.00034276285441592336  accuracy: 9.859166666666667\n",
      "Epoch: 2  batch: 3000  loss: 0.15025417506694794  accuracy: 9.854666666666667\n",
      "Epoch: 2  batch: 3600  loss: 0.07542939484119415  accuracy: 9.856666666666667\n",
      "Epoch: 2  batch: 4200  loss: 0.007790619041770697  accuracy: 9.857619047619048\n",
      "Epoch: 2  batch: 4800  loss: 0.0026458159554749727  accuracy: 9.858541666666667\n",
      "Epoch: 2  batch: 5400  loss: 0.00023519759997725487  accuracy: 9.856111111111112\n",
      "Epoch: 2  batch: 6000  loss: 8.953904762165621e-05  accuracy: 9.856833333333332\n",
      "Epoch: 3  batch: 600  loss: 0.0014694588026031852  accuracy: 9.881666666666666\n",
      "Epoch: 3  batch: 1200  loss: 0.0009278828511014581  accuracy: 9.8925\n",
      "Epoch: 3  batch: 1800  loss: 0.0008325751987285912  accuracy: 9.894444444444444\n",
      "Epoch: 3  batch: 2400  loss: 0.00039477128302678466  accuracy: 9.885\n",
      "Epoch: 3  batch: 3000  loss: 0.14471468329429626  accuracy: 9.884333333333334\n",
      "Epoch: 3  batch: 3600  loss: 0.0014093129429966211  accuracy: 9.883888888888889\n",
      "Epoch: 3  batch: 4200  loss: 0.0016603320837020874  accuracy: 9.883571428571429\n",
      "Epoch: 3  batch: 4800  loss: 0.052508383989334106  accuracy: 9.885\n",
      "Epoch: 3  batch: 5400  loss: 0.0030108848586678505  accuracy: 9.88351851851852\n",
      "Epoch: 3  batch: 6000  loss: 0.0008935341611504555  accuracy: 9.8835\n",
      "Epoch: 4  batch: 600  loss: 0.0030690543353557587  accuracy: 9.933333333333334\n",
      "Epoch: 4  batch: 1200  loss: 0.31129175424575806  accuracy: 9.908333333333333\n",
      "Epoch: 4  batch: 1800  loss: 2.5187715436914004e-05  accuracy: 9.911666666666667\n",
      "Epoch: 4  batch: 2400  loss: 0.00011092839849879965  accuracy: 9.91\n",
      "Epoch: 4  batch: 3000  loss: 0.003968947101384401  accuracy: 9.907333333333334\n",
      "Epoch: 4  batch: 3600  loss: 0.0023413009475916624  accuracy: 9.908055555555556\n",
      "Epoch: 4  batch: 4200  loss: 0.00806394312530756  accuracy: 9.908809523809524\n",
      "Epoch: 4  batch: 4800  loss: 0.0008409325964748859  accuracy: 9.907916666666667\n",
      "Epoch: 4  batch: 5400  loss: 0.00010146030399482697  accuracy: 9.908148148148149\n",
      "Epoch: 4  batch: 6000  loss: 0.004141523502767086  accuracy: 9.908166666666666\n",
      "Duration: 6.984711043039957 mins\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# TRAINING ----\n",
    "epochs = 5\n",
    "\n",
    "# TRACKERS ----\n",
    "train_losses = []  \n",
    "test_losses = []  \n",
    "train_correct = [] \n",
    "test_correct = []\n",
    "\n",
    "# START FOR LOOP EPOCHS\n",
    "for i in range(epochs):\n",
    "    trn_correct = 0\n",
    "    tst_correct = 0\n",
    "\n",
    "    # TRAIN \n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b += 1\n",
    "        y_pred = model(X_train) # No need to Flatten it \n",
    "        loss = criterion(y_pred, y_train)\n",
    "        \n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_correct += batch_corr\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if b % 600 == 0:\n",
    "            accuracy = (trn_correct.item() * 100) / (100 * b)\n",
    "            print(f\"Epoch: {i}  batch: {b}  loss: {loss.item()}  accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "    train_losses.append(loss.detach().numpy())\n",
    "    train_correct.append(trn_correct.item())\n",
    "\n",
    "    \n",
    "    \n",
    "    # TEST\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            b += 1\n",
    "            y_val = model(X_test) \n",
    "            \n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_correct += (predicted == y_test).sum()\n",
    "\n",
    "    loss = criterion(y_val, y_test)  \n",
    "    test_losses.append(loss.detach().numpy()) \n",
    "    test_correct.append(tst_correct.item())\n",
    "\n",
    "\n",
    "\n",
    "# Display the Duration. Time that takes to train the model\n",
    "total_time = time.time() - start  \n",
    "print(f\"Duration: {total_time/60} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dfa297e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot the Losses for Train and Test\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_losses\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining losses\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest losses\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the Losses for Train and Test\n",
    "plt.plot(train_losses, label=\"Training losses\")\n",
    "plt.plot(test_losses, label=\"Test losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot the Accuracy for Train and Test\n",
    "plt.plot([t/600 for t in train_correct], label='Training accuracy')\n",
    "plt.plot([t/100 for t in test_correct], label='Test accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05dc8c",
   "metadata": {},
   "source": [
    "# New Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebff7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_all = DataLoader(test_data, batch_size=10000, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fac4accd",
   "metadata": {},
   "outputs": [],
   "source": [
    " with torch.no_grad():\n",
    "        correct =0 \n",
    "        \n",
    "        for (X_test, y_test) in test_loader_all:\n",
    "            y_val = model(X_test)\n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "\n",
    "            correct += (predicted == y_test).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bee188",
   "metadata": {},
   "source": [
    "# Create a new Prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9e7abae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "         0.6235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.4863, 0.4431,\n",
       "         0.3020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7059, 0.9961, 0.7451,\n",
       "         0.2431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.9961, 0.8000, 0.0863,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1843, 0.4000, 0.8275, 0.6078, 0.0510, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.3804, 0.8235, 0.3725, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.5255, 0.9647, 0.3804, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.1882, 0.9216, 0.7098, 0.0275, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.1255, 0.6549, 0.8235, 0.1961, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.4275, 0.9490, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0941, 0.6980, 0.7569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0588, 0.1373,\n",
       "         0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.2431, 0.8157, 0.0510, 0.0000, 0.1137, 0.4902, 0.7961, 0.8706,\n",
       "         0.7451, 0.4392, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.3255, 0.9961, 0.4902, 0.1098, 0.8039, 1.0000, 0.9961, 0.9961,\n",
       "         0.9765, 0.7647, 0.4157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0941, 0.7255, 0.9961, 0.7020, 0.9765, 0.9412, 0.6039, 0.6235, 0.6667,\n",
       "         0.1373, 0.1529, 0.7255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.5020, 0.9961, 0.9961, 0.6941, 0.0235, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.2902, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0863, 0.9294, 0.9961, 0.7255, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.1255, 0.8314, 0.1137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.2549, 0.9059, 0.7725, 0.8039, 0.0706, 0.0000, 0.0000, 0.0824, 0.0667,\n",
       "         0.8392, 0.5412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.5451, 0.1412, 0.3333, 0.9569, 0.6353, 0.0863, 0.2706, 0.9373, 0.9961,\n",
       "         0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.1294, 0.0745, 0.0627, 0.1647, 0.9020, 0.9412, 0.9961, 0.9961, 0.6314,\n",
       "         0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.6392, 0.7843, 0.4000, 0.0118,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[2000][0].view(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "139a103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.1922, 0.6235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471,\n",
       "           0.4863, 0.4431, 0.3020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7059,\n",
       "           0.9961, 0.7451, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.9961,\n",
       "           0.8000, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1843, 0.4000, 0.8275, 0.6078,\n",
       "           0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.3804, 0.8235, 0.3725, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.5255, 0.9647, 0.3804, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.1882, 0.9216, 0.7098, 0.0275, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.1255, 0.6549, 0.8235, 0.1961, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.4275, 0.9490, 0.1333, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0941, 0.6980, 0.7569, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0588, 0.1373, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.2431, 0.8157, 0.0510, 0.0000, 0.1137, 0.4902,\n",
       "           0.7961, 0.8706, 0.7451, 0.4392, 0.0275, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.3255, 0.9961, 0.4902, 0.1098, 0.8039, 1.0000,\n",
       "           0.9961, 0.9961, 0.9765, 0.7647, 0.4157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0941, 0.7255, 0.9961, 0.7020, 0.9765, 0.9412, 0.6039,\n",
       "           0.6235, 0.6667, 0.1373, 0.1529, 0.7255, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.5020, 0.9961, 0.9961, 0.6941, 0.0235, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.2902, 0.4549, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0863, 0.9294, 0.9961, 0.7255, 0.0745, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.1255, 0.8314, 0.1137, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2549, 0.9059, 0.7725, 0.8039, 0.0706, 0.0000, 0.0000,\n",
       "           0.0824, 0.0667, 0.8392, 0.5412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.5451, 0.1412, 0.3333, 0.9569, 0.6353, 0.0863, 0.2706,\n",
       "           0.9373, 0.9961, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.1294, 0.0745, 0.0627, 0.1647, 0.9020, 0.9412, 0.9961,\n",
       "           0.9961, 0.6314, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.6392, 0.7843,\n",
       "           0.4000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 6)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ea33a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x179d4a15fa0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2, 2))\n",
    "test_data_view = test_data[2000][0].view(28, 28)\n",
    "plt.imshow(test_data_view, cmap=\"gist_yarg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "798dcef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_pred = model(test_data[2000][0].view(1, 1, 28, 28))\n",
    "    predicted = torch.max(new_pred.data, 1)[1]\n",
    "    print(predicted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9781f8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7395652",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = torch.max(new_pred.data, 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c62ef43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bfc76c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "616842d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d699ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e2a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a1ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
