{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e62b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a8834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89681a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb19c682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marya\\anaconda3\\envs\\pytorch_course_env_windows\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root='../Data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53506c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../Data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b7ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(root='../Data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "660b22a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../Data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749483ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3dbeae",
   "metadata": {},
   "source": [
    "# Convolutional Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50c7c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 6, 3, 1) # ----> 6 filters --> pooling --> Conv2 : th output channel will be 6\n",
    "\"\"\"\n",
    "In the layer, we did not add padding, coz in MNIST data, all information on center, so no plm if we loss the border of image\n",
    "\"\"\"\n",
    "# the 6 for input channel com from Conv1, 16 filter (optional)\n",
    "conv2 = nn.Conv2d(6, 16, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc27472",
   "metadata": {},
   "source": [
    "# First Batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4acff501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first batch of data\n",
    "for i, (X_train, y_train) in enumerate(train_data):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92e0dac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0729a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train.view(1, 1, 28, 28) # change it to 4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72d06250",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa99a85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 26, 26])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "\n",
    "# the output will be\n",
    "# [ Number of sample,\n",
    "#   Number of channel(NO.Filter that applied),\n",
    "#   the output size (will be different coz we loss some data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0183652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pooling layer\n",
    "x = F.max_pool2d(x, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9a50d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 13, 13])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "\n",
    "# the output will be\n",
    "# [ Number of sample,\n",
    "#   Number of channel(NO.Filter that applied),\n",
    "#   the output size (will be different coz we apply Max_Pooling with 2*2, that mean cut the size ti half)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c86e3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.relu(conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25c3ea23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 11, 11])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4176260",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = F.max_pool2d(x, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ddea6b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5, 5])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11be2ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the data: To fit it into our model, should be flatten\n",
    "x.view(-1, 16 * 5 * 5).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a955db5",
   "metadata": {},
   "source": [
    "# Create / Build oue MODEL with CNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8fd7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_sz = 5*5*16, out_sz=10, layers=[120, 84]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN layers \n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2= nn.Conv2d(6, 16, 3, 1) # the output will be [1, 16, 5, 5]  --> should reshape it before fit it into full connecting layers \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Full connect Linear Layers \n",
    "        self.fc1 = nn.Linear(in_sz, layers[0])\n",
    "        self.fc2 = nn.Linear(layers[0], layers[1])    \n",
    "        self.fc3 = nn.Linear(layers[1], out_sz) \n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 16 * 5 * 5) # Should be flatten to fit it to full connection layer \n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X)) \n",
    "        X = self.fc3(X)\n",
    "        \n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "19acae9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f48ba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "6\n",
      "864\n",
      "16\n",
      "48000\n",
      "120\n",
      "10080\n",
      "84\n",
      "840\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d94231a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters =  60074\n"
     ]
    }
   ],
   "source": [
    " print('Total Parameters = ', 54 +6 +864 +16 + 48000 +120 +10080 +84 +840 +10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba77bc",
   "metadata": {},
   "source": [
    "# Set the Loss Function and the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ec62dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c69b229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  batch: 600  loss: 0.4123639166355133  accuracy: 9.773333333333333\n",
      "Epoch: 0  batch: 1200  loss: 0.015224682167172432  accuracy: 9.7775\n",
      "Epoch: 0  batch: 1800  loss: 0.001860696473158896  accuracy: 9.777222222222223\n",
      "Epoch: 0  batch: 2400  loss: 0.15397495031356812  accuracy: 9.776666666666667\n",
      "Epoch: 0  batch: 3000  loss: 0.0017277069855481386  accuracy: 9.781666666666666\n",
      "Epoch: 0  batch: 3600  loss: 0.39858224987983704  accuracy: 9.7825\n",
      "Epoch: 0  batch: 4200  loss: 0.0034435850102454424  accuracy: 9.786428571428571\n",
      "Epoch: 0  batch: 4800  loss: 0.2423718422651291  accuracy: 9.790416666666667\n",
      "Epoch: 0  batch: 5400  loss: 0.005317748989909887  accuracy: 9.792592592592593\n",
      "Epoch: 0  batch: 6000  loss: 0.005669874604791403  accuracy: 9.793833333333334\n",
      "Epoch: 1  batch: 600  loss: 0.006469885818660259  accuracy: 9.83\n",
      "Epoch: 1  batch: 1200  loss: 0.0013238077517598867  accuracy: 9.8375\n",
      "Epoch: 1  batch: 1800  loss: 0.00015553270350210369  accuracy: 9.847777777777777\n",
      "Epoch: 1  batch: 2400  loss: 0.003341248957440257  accuracy: 9.84375\n",
      "Epoch: 1  batch: 3000  loss: 0.0035563018172979355  accuracy: 9.838\n",
      "Epoch: 1  batch: 3600  loss: 0.0005446126451715827  accuracy: 9.843055555555555\n",
      "Epoch: 1  batch: 4200  loss: 0.0002351510338485241  accuracy: 9.843809523809524\n",
      "Epoch: 1  batch: 4800  loss: 0.053321290761232376  accuracy: 9.846458333333333\n",
      "Epoch: 1  batch: 5400  loss: 0.019687311723828316  accuracy: 9.846851851851852\n",
      "Epoch: 1  batch: 6000  loss: 0.002524827839806676  accuracy: 9.848166666666666\n",
      "Epoch: 2  batch: 600  loss: 0.0004238602123223245  accuracy: 9.896666666666667\n",
      "Epoch: 2  batch: 1200  loss: 0.00544737046584487  accuracy: 9.88\n",
      "Epoch: 2  batch: 1800  loss: 0.0037922561168670654  accuracy: 9.87888888888889\n",
      "Epoch: 2  batch: 2400  loss: 0.006003167480230331  accuracy: 9.875416666666666\n",
      "Epoch: 2  batch: 3000  loss: 0.06957478076219559  accuracy: 9.875\n",
      "Epoch: 2  batch: 3600  loss: 0.3427119851112366  accuracy: 9.879722222222222\n",
      "Epoch: 2  batch: 4200  loss: 0.0002831656893249601  accuracy: 9.882619047619048\n",
      "Epoch: 2  batch: 4800  loss: 0.004104991443455219  accuracy: 9.881458333333333\n",
      "Epoch: 2  batch: 5400  loss: 0.27843421697616577  accuracy: 9.880740740740741\n",
      "Epoch: 2  batch: 6000  loss: 0.004091357346624136  accuracy: 9.881166666666667\n",
      "Epoch: 3  batch: 600  loss: 0.0017628520727157593  accuracy: 9.911666666666667\n",
      "Epoch: 3  batch: 1200  loss: 0.012957816943526268  accuracy: 9.92\n",
      "Epoch: 3  batch: 1800  loss: 0.0012883072486147285  accuracy: 9.91611111111111\n",
      "Epoch: 3  batch: 2400  loss: 0.006235552951693535  accuracy: 9.909583333333334\n",
      "Epoch: 3  batch: 3000  loss: 0.02819032594561577  accuracy: 9.905333333333333\n",
      "Epoch: 3  batch: 3600  loss: 0.004095637239515781  accuracy: 9.903055555555556\n",
      "Epoch: 3  batch: 4200  loss: 0.0007460516644641757  accuracy: 9.903095238095238\n",
      "Epoch: 3  batch: 4800  loss: 0.0010879506589844823  accuracy: 9.903541666666667\n",
      "Epoch: 3  batch: 5400  loss: 0.00013797639985568821  accuracy: 9.899814814814814\n",
      "Epoch: 3  batch: 6000  loss: 0.025575214996933937  accuracy: 9.900166666666667\n",
      "Epoch: 4  batch: 600  loss: 0.0008347284747287631  accuracy: 9.933333333333334\n",
      "Epoch: 4  batch: 1200  loss: 0.09227162599563599  accuracy: 9.9375\n",
      "Epoch: 4  batch: 1800  loss: 0.0003700049128383398  accuracy: 9.934444444444445\n",
      "Epoch: 4  batch: 2400  loss: 0.0005717353196814656  accuracy: 9.932916666666667\n",
      "Epoch: 4  batch: 3000  loss: 0.002561694011092186  accuracy: 9.927333333333333\n",
      "Epoch: 4  batch: 3600  loss: 0.00014131281932350248  accuracy: 9.924722222222222\n",
      "Epoch: 4  batch: 4200  loss: 0.2817588746547699  accuracy: 9.925238095238095\n",
      "Epoch: 4  batch: 4800  loss: 5.041813710704446e-05  accuracy: 9.92375\n",
      "Epoch: 4  batch: 5400  loss: 0.000233588318224065  accuracy: 9.921851851851851\n",
      "Epoch: 4  batch: 6000  loss: 0.0002725549857132137  accuracy: 9.921666666666667\n",
      "Epoch: 5  batch: 600  loss: 0.00041702770977281034  accuracy: 9.943333333333333\n",
      "Epoch: 5  batch: 1200  loss: 9.542168118059635e-05  accuracy: 9.929166666666667\n",
      "Epoch: 5  batch: 1800  loss: 0.00036095347604714334  accuracy: 9.925555555555556\n",
      "Epoch: 5  batch: 2400  loss: 2.7033767764805816e-05  accuracy: 9.93125\n",
      "Epoch: 5  batch: 3000  loss: 0.337580144405365  accuracy: 9.930666666666667\n",
      "Epoch: 5  batch: 3600  loss: 0.004922838415950537  accuracy: 9.928333333333333\n",
      "Epoch: 5  batch: 4200  loss: 0.012347454205155373  accuracy: 9.925952380952381\n",
      "Epoch: 5  batch: 4800  loss: 4.4769960368284956e-05  accuracy: 9.923333333333334\n",
      "Epoch: 5  batch: 5400  loss: 0.0019576894119381905  accuracy: 9.921481481481482\n",
      "Epoch: 5  batch: 6000  loss: 6.436997500713915e-05  accuracy: 9.920833333333333\n",
      "Epoch: 6  batch: 600  loss: 1.1491566510812845e-05  accuracy: 9.961666666666666\n",
      "Epoch: 6  batch: 1200  loss: 0.07135391980409622  accuracy: 9.956666666666667\n",
      "Epoch: 6  batch: 1800  loss: 0.0001279026037082076  accuracy: 9.951666666666666\n",
      "Epoch: 6  batch: 2400  loss: 0.0033279680646955967  accuracy: 9.949583333333333\n",
      "Epoch: 6  batch: 3000  loss: 0.00039942882722243667  accuracy: 9.944666666666667\n",
      "Epoch: 6  batch: 3600  loss: 0.0011342440266162157  accuracy: 9.944722222222222\n",
      "Epoch: 6  batch: 4200  loss: 0.004438245203346014  accuracy: 9.94595238095238\n",
      "Epoch: 6  batch: 4800  loss: 0.0006558506865985692  accuracy: 9.944791666666667\n",
      "Epoch: 6  batch: 5400  loss: 0.0012868379708379507  accuracy: 9.943148148148149\n",
      "Epoch: 6  batch: 6000  loss: 0.10504108667373657  accuracy: 9.940166666666666\n",
      "Epoch: 7  batch: 600  loss: 0.006356825120747089  accuracy: 9.93\n",
      "Epoch: 7  batch: 1200  loss: 0.001273777219466865  accuracy: 9.930833333333334\n",
      "Epoch: 7  batch: 1800  loss: 0.0003034176188521087  accuracy: 9.943333333333333\n",
      "Epoch: 7  batch: 2400  loss: 0.0011849936563521624  accuracy: 9.94375\n",
      "Epoch: 7  batch: 3000  loss: 0.0003923160838894546  accuracy: 9.943\n",
      "Epoch: 7  batch: 3600  loss: 0.0015855565434321761  accuracy: 9.943333333333333\n",
      "Epoch: 7  batch: 4200  loss: 0.0004666453169193119  accuracy: 9.942619047619047\n",
      "Epoch: 7  batch: 4800  loss: 0.0005578183336183429  accuracy: 9.943125\n",
      "Epoch: 7  batch: 5400  loss: 6.459160795202479e-05  accuracy: 9.943518518518518\n",
      "Epoch: 7  batch: 6000  loss: 4.282732697902247e-05  accuracy: 9.942833333333333\n",
      "Epoch: 8  batch: 600  loss: 1.0478031981620006e-05  accuracy: 9.95\n",
      "Epoch: 8  batch: 1200  loss: 1.9918841644539498e-05  accuracy: 9.95\n",
      "Epoch: 8  batch: 1800  loss: 0.0002526736643631011  accuracy: 9.952777777777778\n",
      "Epoch: 8  batch: 2400  loss: 0.008788101375102997  accuracy: 9.9525\n",
      "Epoch: 8  batch: 3000  loss: 0.0015095619019120932  accuracy: 9.951666666666666\n",
      "Epoch: 8  batch: 3600  loss: 3.802728770097019e-06  accuracy: 9.953333333333333\n",
      "Epoch: 8  batch: 4200  loss: 2.2933354557608254e-05  accuracy: 9.950714285714286\n",
      "Epoch: 8  batch: 4800  loss: 0.00023055903147906065  accuracy: 9.950625\n",
      "Epoch: 8  batch: 5400  loss: 0.008548724465072155  accuracy: 9.950185185185186\n",
      "Epoch: 8  batch: 6000  loss: 7.082133379299194e-05  accuracy: 9.9485\n",
      "Epoch: 9  batch: 600  loss: 0.001586051657795906  accuracy: 9.951666666666666\n",
      "Epoch: 9  batch: 1200  loss: 0.0021204915829002857  accuracy: 9.961666666666666\n",
      "Epoch: 9  batch: 1800  loss: 5.388157660490833e-06  accuracy: 9.96\n",
      "Epoch: 9  batch: 2400  loss: 2.4984503397718072e-05  accuracy: 9.96\n",
      "Epoch: 9  batch: 3000  loss: 0.0013090349966660142  accuracy: 9.959\n",
      "Epoch: 9  batch: 3600  loss: 1.1062084013246931e-05  accuracy: 9.960555555555555\n",
      "Epoch: 9  batch: 4200  loss: 0.16744959354400635  accuracy: 9.958809523809524\n",
      "Epoch: 9  batch: 4800  loss: 0.006208765786141157  accuracy: 9.956875\n",
      "Epoch: 9  batch: 5400  loss: 0.01315579004585743  accuracy: 9.957037037037036\n",
      "Epoch: 9  batch: 6000  loss: 1.3828221199219115e-06  accuracy: 9.954\n",
      "Duration: 3.5259385148684186 mins\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# TRAINING ----\n",
    "epochs = 10  \n",
    "\n",
    "# TRACKERS ----\n",
    "train_losses = []  \n",
    "test_losses = []  \n",
    "train_correct = [] \n",
    "test_correct = []\n",
    "\n",
    "# START FOR LOOP EPOCHS\n",
    "for i in range(epochs):\n",
    "    trn_correct = 0\n",
    "    tst_correct = 0\n",
    "\n",
    "    # TRAIN \n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b += 1\n",
    "        y_pred = model(X_train) # No need to Flatten it \n",
    "        loss = criterion(y_pred, y_train)\n",
    "        \n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_correct += batch_corr\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if b % 600 == 0:\n",
    "            accuracy = (trn_correct.item() * 100) / (100 * b)\n",
    "            print(f\"Epoch: {i}  batch: {b}  loss: {loss.item()}  accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_correct)\n",
    "\n",
    "    \n",
    "    \n",
    "    # TEST\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            b += 1\n",
    "            y_val = model(X_test) \n",
    "            \n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_correct += (predicted == y_test).sum()\n",
    "\n",
    "    loss = criterion(y_val, y_test)  \n",
    "    test_losses.append(loss.detach().numpy()) \n",
    "    test_correct.append(tst_correct.item())\n",
    "\n",
    "\n",
    "\n",
    "# Display the Duration. Time that takes to train the model\n",
    "total_time = time.time() - start  \n",
    "print(f\"Duration: {total_time/60} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7a78a4cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_course_env_windows\\lib\\site-packages\\matplotlib\\pyplot.py:3019\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 3019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3020\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3021\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_course_env_windows\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1605\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1604\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1605\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_course_env_windows\\lib\\site-packages\\matplotlib\\axes\\_base.py:315\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    314\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_course_env_windows\\lib\\site-packages\\matplotlib\\axes\\_base.py:493\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[43mindex_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mupdate_units(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_course_env_windows\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1687\u001b[0m, in \u001b[0;36mindex_of\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1687\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mVisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1689\u001b[0m     \u001b[38;5;66;03m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_course_env_windows\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1339\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1341\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1342\u001b[0m         \u001b[38;5;66;03m# work around\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m         \u001b[38;5;66;03m# https://github.com/pandas-dev/pandas/issues/27775 which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1354\u001b[0m         \u001b[38;5;66;03m# This code should correctly identify and coerce to a\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m         \u001b[38;5;66;03m# numpy array all pandas versions.\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_course_env_windows\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[1;32m---> 65\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_course_env_windows\\lib\\site-packages\\torch\\_tensor.py:643\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa297e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
